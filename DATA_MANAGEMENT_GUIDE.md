# H∆∞·ªõng d·∫´n Qu·∫£n l√Ω D·ªØ li·ªáu - Export/Import

## T·ªïng quan

H·ªá th·ªëng rental-web cung c·∫•p c√°c c√¥ng c·ª• m·∫°nh m·∫Ω ƒë·ªÉ export v√† import d·ªØ li·ªáu, gi√∫p b·∫£o v·ªá v√† qu·∫£n l√Ω d·ªØ li·ªáu ng∆∞·ªùi d√πng m·ªôt c√°ch an to√†n v√† hi·ªáu qu·∫£.

## üì• Export D·ªØ li·ªáu

### T√≠nh nƒÉng ch√≠nh
- ‚úÖ **Multi-format**: JSON, CSV
- ‚úÖ **Compression**: ZIP v·ªõi t·ª∑ l·ªá n√©n cao
- ‚úÖ **User filtering**: Export theo user c·ª• th·ªÉ (admin)
- ‚úÖ **Table selection**: Ch·ªçn b·∫£ng c·ª• th·ªÉ ƒë·ªÉ export
- ‚úÖ **Date range**: Filter theo kho·∫£ng th·ªùi gian
- ‚úÖ **Progress tracking**: Theo d√µi ti·∫øn ƒë·ªô realtime
- ‚úÖ **Comprehensive logging**: Log chi ti·∫øt v√† b√°o c√°o

### S·ª≠ d·ª•ng c∆° b·∫£n

#### 1. Export t·∫•t c·∫£ d·ªØ li·ªáu (JSON)
```bash
node scripts/export-data.js
```

#### 2. Export v·ªõi compression
```bash
node scripts/export-data.js --compress
```

#### 3. Export CSV format
```bash
node scripts/export-data.js --format csv --compress
```

#### 4. Export v·ªõi invoices v√† utilities
```bash
node scripts/export-data.js --include-invoices --include-utilities
```

### T√πy ch·ªçn n√¢ng cao

#### Export theo user c·ª• th·ªÉ (Admin only)
```bash
node scripts/export-data.js --user-id abc123 --format json
```

#### Export theo date range
```bash
node scripts/export-data.js --date-range "2024-01-01:2024-12-31" --include-invoices
```

#### Export tables c·ª• th·ªÉ
```bash
node scripts/export-data.js --tables "properties,rooms" --format csv
```

#### Specify output path
```bash
node scripts/export-data.js --output exports/my-backup.json --compress
```

### CLI Options ƒë·∫ßy ƒë·ªß

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `--format` | string | json | Export format (json/csv) |
| `--output` | string | auto | Custom output file path |
| `--user-id` | string | - | Export for specific user (admin only) |
| `--include-invoices` | boolean | false | Include invoices & payment records |
| `--include-utilities` | boolean | false | Include utilities & bills |
| `--compress` | boolean | false | Compress with ZIP |
| `--date-range` | string | - | Filter by date (YYYY-MM-DD:YYYY-MM-DD) |
| `--tables` | string | all | Tables to export (comma separated) |
| `--batch-size` | number | 1000 | Records per batch |

## üì§ Import D·ªØ li·ªáu

### T√≠nh nƒÉng ch√≠nh
- ‚úÖ **Multi-format**: JSON, CSV, ZIP
- ‚úÖ **Auto-detection**: T·ª± ƒë·ªông ph√°t hi·ªán format
- ‚úÖ **Validation**: Validate d·ªØ li·ªáu tr∆∞·ªõc khi import
- ‚úÖ **Merge strategies**: Skip, Replace, Merge
- ‚úÖ **Deduplication**: Tr√°nh t·∫°o records tr√πng l·∫∑p
- ‚úÖ **Dry-run mode**: Test tr∆∞·ªõc khi import th·∫≠t
- ‚úÖ **Batch processing**: X·ª≠ l√Ω theo batch v·ªõi concurrency
- ‚úÖ **Error handling**: Robust error handling & reporting

### S·ª≠ d·ª•ng c∆° b·∫£n

#### 1. Validate d·ªØ li·ªáu tr∆∞·ªõc khi import
```bash
node scripts/import-data.js --input exports/rental-export-20241201.json --validate-only
```

#### 2. Dry run (test import)
```bash
node scripts/import-data.js --input exports/rental-export-20241201.json --dry-run
```

#### 3. Import th·ª±c t·∫ø
```bash
node scripts/import-data.js --input exports/rental-export-20241201.json
```

### Merge Strategies

#### Skip (Default) - B·ªè qua records ƒë√£ t·ªìn t·∫°i
```bash
node scripts/import-data.js --input data.json --merge-strategy skip
```

#### Replace - Thay th·∫ø records ƒë√£ t·ªìn t·∫°i
```bash
node scripts/import-data.js --input data.json --merge-strategy replace
```

#### Merge - Ch·ªâ c·∫≠p nh·∫≠t fields non-null
```bash
node scripts/import-data.js --input data.json --merge-strategy merge
```

### T√πy ch·ªçn n√¢ng cao

#### Import CSV directory
```bash
node scripts/import-data.js --input exports/csv-export-20241201/
```

#### Import ZIP file
```bash
node scripts/import-data.js --input exports/rental-export-20241201.zip
```

#### Import tables c·ª• th·ªÉ
```bash
node scripts/import-data.js --input data.json --tables "properties,rooms"
```

#### Import v·ªõi batch size nh·ªè h∆°n
```bash
node scripts/import-data.js --input data.json --batch-size 50
```

### CLI Options ƒë·∫ßy ƒë·ªß

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `--input` | string | **required** | Input file path (JSON/CSV/ZIP) |
| `--format` | string | auto | Input format (auto-detected) |
| `--dry-run` | boolean | false | Preview import without writing DB |
| `--validate-only` | boolean | false | Only validate data structure |
| `--user-id` | string | - | Import for specific user (admin only) |
| `--merge-strategy` | string | skip | Handle existing records (skip/replace/merge) |
| `--tables` | string | all | Tables to import (comma separated) |
| `--batch-size` | number | 100 | Records per batch |

## üîÑ Workflow Examples

### 1. Complete Backup & Restore
```bash
# 1. Create full backup
node scripts/export-data.js --format json --compress --include-invoices --include-utilities

# 2. Validate backup
node scripts/import-data.js --input exports/rental-export-20241201.zip --validate-only

# 3. Test restore (dry-run)
node scripts/import-data.js --input exports/rental-export-20241201.zip --dry-run

# 4. Actual restore
node scripts/import-data.js --input exports/rental-export-20241201.zip --merge-strategy replace
```

### 2. Data Migration Between Environments
```bash
# Export from staging
node scripts/export-data.js --format csv --output staging-data --include-invoices

# Import to production
node scripts/import-data.js --input staging-data.zip --merge-strategy merge
```

### 3. Partial Data Sync
```bash
# Export only properties & rooms
node scripts/export-data.js --tables "properties,rooms" --date-range "2024-01-01:2024-12-31"

# Import with skip strategy (no overwrites)
node scripts/import-data.js --input exports/rental-export.json --merge-strategy skip
```

## üìä Output Files & Structure

### Export Outputs

#### JSON Format
```json
{
  "metadata": {
    "exportId": "EXP-20241201-143052-abc123",
    "timestamp": "2024-12-01T14:30:52.123Z",
    "version": "1.0",
    "userId": "user_123",
    "format": "json",
    "tables": ["properties", "rooms", "tenants"],
    "recordCounts": {
      "properties": 5,
      "rooms": 25,
      "tenants": 18
    }
  },
  "data": {
    "properties": [...],
    "rooms": [...],
    "tenants": [...]
  }
}
```

#### CSV Format (directory structure)
```
rental-export-20241201/
‚îú‚îÄ‚îÄ metadata.json
‚îú‚îÄ‚îÄ properties.csv
‚îú‚îÄ‚îÄ rooms.csv
‚îú‚îÄ‚îÄ tenants.csv
‚îî‚îÄ‚îÄ rental_contracts.csv
```

### Generated Files
- `exports/rental-export-YYYYMMDD-HHMMSS-{userId}.{ext}` - Data export
- `logs/export-YYYYMMDD-HHMMSS.log` - Export logs
- `logs/export-report-YYYYMMDD-HHMMSS.json` - Export report
- `logs/import-YYYYMMDD-HHMMSS.log` - Import logs  
- `logs/import-report-YYYYMMDD-HHMMSS.json` - Import report

## üîê Security & Best Practices

### Data Protection
1. **Always backup before major operations**
2. **Use --validate-only and --dry-run first**
3. **Check logs and reports for errors**
4. **Store backups securely**
5. **Use compression for large exports**

### User Isolation
- Regular users: only their own data
- Admin users: can specify --user-id for any user
- RLS (Row Level Security) enforcement

### Error Recovery
1. Check logs in `logs/` directory
2. Review validation reports
3. Use appropriate merge strategy
4. Run incremental imports if needed

## üö® Troubleshooting

### Common Issues

#### 1. "Missing SUPABASE credentials"
```bash
# Check environment file
cat .env.local | grep SUPABASE
```

#### 2. "Validation error rate too high"
```bash
# Run validation-only to see details
node scripts/import-data.js --input data.json --validate-only
```

#### 3. "No data found to export"
- Check user permissions
- Verify database has data
- Check table names are correct

#### 4. "Memory issues with large exports"
```bash
# Use smaller batch sizes
node scripts/export-data.js --batch-size 500
```

### Performance Tuning

#### For Large Datasets
```bash
# Export with smaller batches
node scripts/export-data.js --batch-size 500

# Import with lower concurrency
node scripts/import-data.js --input data.json --batch-size 50
```

#### For Network Issues
```bash
# Increase retry behavior (built-in)
# Use compression to reduce transfer size
node scripts/export-data.js --compress
```

## üìà Monitoring & Reports

### Export Report Example
```json
{
  "exportId": "EXP-20241201-143052-abc123",
  "duration": "45s",
  "results": {
    "totalRecords": 156,
    "totalSize": "2.3 MB",
    "tables": {
      "properties": {"recordCount": 5, "size": "1024"},
      "rooms": {"recordCount": 25, "size": "15360"}
    },
    "errors": []
  }
}
```

### Import Report Example
```json
{
  "importId": "IMP-20241201-143052-def456", 
  "duration": "32s",
  "results": {
    "totalRecords": 156,
    "inserted": 45,
    "updated": 23,
    "skipped": 88,
    "errors": 0
  }
}
```

## üîó Integration v·ªõi Automation

### Scheduled Backups
```bash
# Daily backup script
#!/bin/bash
DATE=$(date +%Y%m%d)
node scripts/export-data.js \
  --format json \
  --compress \
  --include-invoices \
  --output "backups/daily-backup-$DATE.json"
```

### CI/CD Integration
```yaml
# GitHub Actions example
- name: Export staging data
  run: node scripts/export-data.js --format json --output staging-data.json

- name: Import to production
  run: node scripts/import-data.js --input staging-data.json --dry-run
```

---

## üìû Support

- üìã **Check logs**: `logs/export-*.log`, `logs/import-*.log`
- üìä **Check reports**: `logs/*-report-*.json`  
- üîç **Enable debug**: Set higher batch-size for more verbose logs
- üìß **Need help**: Include log files and command used